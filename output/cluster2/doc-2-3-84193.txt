Filename: /home/dev/scikit_learn_data/20news_home/20news-bydate-test/talk.religion.misc/84193
Truth category: 3 (talk.religion.misc)
Assigned cluster: 2 (god christian jesus moral say peopl koresh bibl object believ)

Raw data:
============ START RAW ==========================
From: livesey@solntze.wpd.sgi.com (Jon Livesey)
Subject: Re: After 2000 years, can we say that Christian Morality is
Organization: sgi
Lines: 51
Distribution: world
NNTP-Posting-Host: solntze.wpd.sgi.com

In article <1r3570$hkv@horus.ap.mchp.sni.de>, frank@D012S658.uucp (Frank O'Dwyer) writes:
|> In article <1r2ls3$8mo@fido.asd.sgi.com> livesey@solntze.wpd.sgi.com (Jon Livesey) writes:
|> #|> 
|> #|> #This is quite different from saying "Employing force on other people
|> #|> #is immoral, period.   Unfortunately, from time to time we are obliged
|> #|> #to do this immoral thing for reasons of self-preservation, and so
|> #|> #we have to bear the moral consequences of that.
|> #|> 
|> #|> Since both statements, to all intents and purposes, say effectively
|> #|> the same thing, 
|> #
|> #Are you serious?  Two statements, one of which says that use of force
|> #in the given situation is moral, and the other of which says it is
|> #not moral "say effectively the same thing?"
|> 
|> Yes, when you tag on the "Unfortunately, ...", then to all intents and
|> purposes you are saying the same thing.

Then delete the "unfortunately".   Now tell me that the two statement
say effectively the same thing.

And to save everyone a couple of trips round this loop, please notice
that we are only obliged to use force to preserve self.   We can choose
*not* to preserve self, which is the point of pacifism.

|> 
|> #Would you say this of any two statements, one saying "X is moral" and
|> #the other saying "X is immoral?"   How would you decided when two 
|> #statements "X is moral" "X is immoral" actually conflict, and when
|> #they "say effectively the same thing".
|> 
|> What they prescribe that one should do is a pretty good indicator.

And in this case they don't prescribe the same things, so.....

|> 
|> #|>                  and lead one to do precisely the same thing, then 
|> #|> either both statements are doublespeak, or none.
|> #
|> #They might lead you to do the same thing, but the difference is what
|> #motivates pacifism so they obviously don't lead pacifists to to the
|> #same thing.
|> 
|> That's not true.  You could formulate a pragmatic belief in minimum 
|> force and still be a pacifist.  If the minimum is 0, great  - but one is
|> always trying to get as close to 0 force as possible under that belief.
|> Not the same as 'force is immoral, period', but still tending to pacifism.

If you don't think the use of force is immoral, why minimise its use?

jon.

========== END RAW ============================

Preprocessed:
============ START PREPROCESSED =================
 year say christian moral         quit differ say
employ forc peopl immor period unfortun time time
oblig immor thing reason self preserv bear moral
consequ  sinc statement intent purpos say effect
thing  serious two statement one say use forc
given situat moral say moral say effect thing  yes
tag unfortun intent purpos say thing  delet
unfortun tell two statement say effect thing  save
everyon coupl trip round loop pleas notic oblig
use forc preserv self choos preserv self point
pacif   say two statement one say moral say immor
decid two statement moral immor actual conflict
say effect thing  prescrib one pretti good indic
case don't prescrib thing   lead one precis thing
either statement doublespeak none  might lead
thing differ motiv pacif obvious don't lead
pacifist thing  that true could formul pragmat
belief minimum forc still pacifist minimum great
one alway tri get close forc possibl belief forc
immor period still tend pacif  don't think use
forc immor minimis use  jon
========== END PREPROCESSED =====================


Feature vector (sorted, non-zero values only):
Term, Index, Value:
immor, 4531, 0.403377563443
say, 7653, 0.31947042703
forc, 3594, 0.303923225307
thing, 8869, 0.286467741437
statement, 8343, 0.283822057259
moral, 5855, 0.282082333525
preserv, 6838, 0.191670864308
pacif, 6372, 0.187649482131
effect, 3005, 0.168103413216
prescrib, 6834, 0.163532552982
pacifist, 6373, 0.163532552982
unfortun, 9264, 0.149524243201
self, 7776, 0.145985910819
oblig, 6175, 0.127780576205
lead, 5172, 0.127719219325
minimum, 5740, 0.11186062313
intent, 4702, 0.109740435379
belief, 1008, 0.0975482421481
period, 6546, 0.093463141409
use, 9363, 0.0926350762781
purpos, 6993, 0.0902037968421
pragmat, 6797, 0.0817662764908
don, 2811, 0.0713540502802
formul, 3613, 0.0711586293945
tag, 8673, 0.0659945210027
differ, 2633, 0.064576195246
jon, 4887, 0.0638902881027
loop, 5344, 0.0634241669232
conflict, 2034, 0.0625498273771
motiv, 5881, 0.060294169464
consequ, 2057, 0.0596385810046
round, 7494, 0.0581592308321
trip, 9104, 0.0568630148976
employ, 3077, 0.0568630148976
bear, 971, 0.0528580485938
choos, 1720, 0.0523702397128
tend, 8783, 0.0520572015431
precis, 6809, 0.0508908895403
time, 8936, 0.0498299073653
notic, 6120, 0.0484412042255
indic, 4600, 0.0456732615285
decid, 2442, 0.0454245700319
delet, 2502, 0.0449442112399
obvious, 6185, 0.0443361568599
situat, 7995, 0.0442625705934
coupl, 2187, 0.0436225482485
save, 7646, 0.0422051055311
everyon, 3241, 0.0417915195313
close, 1830, 0.0397453809623
alway, 457, 0.0396033562187
pretti, 6851, 0.0384469483488
quit, 7043, 0.0384049202367
yes, 9951, 0.0381972698881
given, 3887, 0.0376368158995
true, 9121, 0.0374054976973
christian, 1732, 0.0372165556497
case, 1540, 0.0364582011969
great, 4016, 0.0348766723847
possibl, 6765, 0.0343793351069
tell, 8767, 0.0342656646177
reason, 7156, 0.0338229181178
actual, 254, 0.0337150919755
sinc, 7977, 0.0319654260121
pleas, 6688, 0.0308470063052
tri, 9087, 0.0303684746077
point, 6710, 0.0295983416944
peopl, 6530, 0.0284501558844
good, 3948, 0.0269550125761
year, 9943, 0.0263533038533
think, 8871, 0.0240160789733
